/**
 * Generated by Scrooge
 *   version: 18.10.0
 *   rev: dda071e1412b53f4bfdebc19e474f584e475d475
 *   built at: 20181018-174244
 */
package modeldb

import com.twitter.io.Buf
import com.twitter.scrooge.{
  LazyTProtocol,
  TFieldBlob,
  ThriftException,
  ThriftStruct,
  ThriftStructCodec3,
  ThriftStructFieldInfo,
  ThriftStructMetaData,
  ThriftUtil,
  ValidatingThriftStruct,
  ValidatingThriftStructCodec3
}
import org.apache.thrift.protocol._
import org.apache.thrift.transport.{TMemoryBuffer, TTransport, TIOStreamTransport}
import java.io.ByteArrayInputStream
import java.nio.ByteBuffer
import java.util.Arrays
import java.util.concurrent.atomic.AtomicInteger
import scala.collection.immutable.{Map => immutable$Map}
import scala.collection.mutable.Builder
import scala.collection.mutable.{
  ArrayBuffer => mutable$ArrayBuffer, Buffer => mutable$Buffer,
  HashMap => mutable$HashMap, HashSet => mutable$HashSet}
import scala.collection.{Map, Set}


object TransformEventResponse extends ValidatingThriftStructCodec3[TransformEventResponse] {
  val NoPassthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty[Short, TFieldBlob]
  val Struct: TStruct = new TStruct("TransformEventResponse")
  val OldDataFrameIdField: TField = new TField("oldDataFrameId", TType.I32, 1)
  val OldDataFrameIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val NewDataFrameIdField: TField = new TField("newDataFrameId", TType.I32, 2)
  val NewDataFrameIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val TransformerIdField: TField = new TField("transformerId", TType.I32, 3)
  val TransformerIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val EventIdField: TField = new TField("eventId", TType.I32, 4)
  val EventIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val FilepathField: TField = new TField("filepath", TType.STRING, 5)
  val FilepathFieldManifest: Manifest[String] = implicitly[Manifest[String]]

  /**
   * Field information in declaration order.
   */
  lazy val fieldInfos: scala.List[ThriftStructFieldInfo] = scala.List[ThriftStructFieldInfo](
    new ThriftStructFieldInfo(
      OldDataFrameIdField,
      false,
      false,
      OldDataFrameIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      NewDataFrameIdField,
      false,
      false,
      NewDataFrameIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      TransformerIdField,
      false,
      false,
      TransformerIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      EventIdField,
      false,
      false,
      EventIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      FilepathField,
      false,
      false,
      FilepathFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    )
  )

  lazy val structAnnotations: immutable$Map[String, String] =
    immutable$Map.empty[String, String]

  /**
   * Checks that all required fields are non-null.
   */
  def validate(_item: TransformEventResponse): Unit = {
  }

  /**
   * Checks that the struct is a valid as a new instance. If there are any missing required or
   * construction required fields, return a non-empty list.
   */
  def validateNewInstance(item: TransformEventResponse): scala.Seq[com.twitter.scrooge.validation.Issue] = {
    val buf = scala.collection.mutable.ListBuffer.empty[com.twitter.scrooge.validation.Issue]

    buf ++= validateField(item.oldDataFrameId)
    buf ++= validateField(item.newDataFrameId)
    buf ++= validateField(item.transformerId)
    buf ++= validateField(item.eventId)
    buf ++= validateField(item.filepath)
    buf.toList
  }

  def withoutPassthroughFields(original: TransformEventResponse): TransformEventResponse =
    new Immutable(
      oldDataFrameId =
        {
          val field = original.oldDataFrameId
          field
        },
      newDataFrameId =
        {
          val field = original.newDataFrameId
          field
        },
      transformerId =
        {
          val field = original.transformerId
          field
        },
      eventId =
        {
          val field = original.eventId
          field
        },
      filepath =
        {
          val field = original.filepath
          field
        }
    )

  override def encode(_item: TransformEventResponse, _oproto: TProtocol): Unit = {
    _item.write(_oproto)
  }


  private[this] def lazyDecode(_iprot: LazyTProtocol): TransformEventResponse = {

    var oldDataFrameId: Int = 0
    var newDataFrameId: Int = 0
    var transformerId: Int = 0
    var eventId: Int = 0
    var filepathOffset: Int = -1

    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false
    val _start_offset = _iprot.offset

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.I32 =>
    
                oldDataFrameId = readOldDataFrameIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'oldDataFrameId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.I32 =>
    
                newDataFrameId = readNewDataFrameIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'newDataFrameId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.I32 =>
    
                transformerId = readTransformerIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'transformerId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.I32 =>
    
                eventId = readEventIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'eventId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.STRING =>
                filepathOffset = _iprot.offsetSkipString
    
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'filepath' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    new LazyImmutable(
      _iprot,
      _iprot.buffer,
      _start_offset,
      _iprot.offset,
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepathOffset,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  override def decode(_iprot: TProtocol): TransformEventResponse =
    _iprot match {
      case i: LazyTProtocol => lazyDecode(i)
      case i => eagerDecode(i)
    }

  private[modeldb] def eagerDecode(_iprot: TProtocol): TransformEventResponse = {
    var oldDataFrameId: Int = 0
    var newDataFrameId: Int = 0
    var transformerId: Int = 0
    var eventId: Int = 0
    var filepath: String = null
    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.I32 =>
                oldDataFrameId = readOldDataFrameIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'oldDataFrameId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.I32 =>
                newDataFrameId = readNewDataFrameIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'newDataFrameId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.I32 =>
                transformerId = readTransformerIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'transformerId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.I32 =>
                eventId = readEventIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'eventId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.STRING =>
                filepath = readFilepathValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'filepath' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    new Immutable(
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  def apply(
    oldDataFrameId: Int,
    newDataFrameId: Int,
    transformerId: Int,
    eventId: Int,
    filepath: String
  ): TransformEventResponse =
    new Immutable(
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath
    )

  def unapply(_item: TransformEventResponse): _root_.scala.Option[_root_.scala.Tuple5[Int, Int, Int, Int, String]] = _root_.scala.Some(_item.toTuple)


  @inline private[modeldb] def readOldDataFrameIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeOldDataFrameIdField(oldDataFrameId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(OldDataFrameIdField)
    writeOldDataFrameIdValue(oldDataFrameId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeOldDataFrameIdValue(oldDataFrameId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(oldDataFrameId_item)
  }

  @inline private[modeldb] def readNewDataFrameIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeNewDataFrameIdField(newDataFrameId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(NewDataFrameIdField)
    writeNewDataFrameIdValue(newDataFrameId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeNewDataFrameIdValue(newDataFrameId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(newDataFrameId_item)
  }

  @inline private[modeldb] def readTransformerIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeTransformerIdField(transformerId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(TransformerIdField)
    writeTransformerIdValue(transformerId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeTransformerIdValue(transformerId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(transformerId_item)
  }

  @inline private[modeldb] def readEventIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeEventIdField(eventId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(EventIdField)
    writeEventIdValue(eventId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeEventIdValue(eventId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(eventId_item)
  }

  @inline private[modeldb] def readFilepathValue(_iprot: TProtocol): String = {
    _iprot.readString()
  }

  @inline private def writeFilepathField(filepath_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(FilepathField)
    writeFilepathValue(filepath_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeFilepathValue(filepath_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeString(filepath_item)
  }


  object Immutable extends ThriftStructCodec3[TransformEventResponse] {
    override def encode(_item: TransformEventResponse, _oproto: TProtocol): Unit = { _item.write(_oproto) }
    override def decode(_iprot: TProtocol): TransformEventResponse = TransformEventResponse.decode(_iprot)
    override lazy val metaData: ThriftStructMetaData[TransformEventResponse] = TransformEventResponse.metaData
  }

  /**
   * The default read-only implementation of TransformEventResponse.  You typically should not need to
   * directly reference this class; instead, use the TransformEventResponse.apply method to construct
   * new instances.
   */
  class Immutable(
      val oldDataFrameId: Int,
      val newDataFrameId: Int,
      val transformerId: Int,
      val eventId: Int,
      val filepath: String,
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends TransformEventResponse {
    def this(
      oldDataFrameId: Int,
      newDataFrameId: Int,
      transformerId: Int,
      eventId: Int,
      filepath: String
    ) = this(
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath,
      Map.empty[Short, TFieldBlob]
    )
  }

  /**
   * This is another Immutable, this however keeps strings as lazy values that are lazily decoded from the backing
   * array byte on read.
   */
  private[this] class LazyImmutable(
      _proto: LazyTProtocol,
      _buf: Array[Byte],
      _start_offset: Int,
      _end_offset: Int,
      val oldDataFrameId: Int,
      val newDataFrameId: Int,
      val transformerId: Int,
      val eventId: Int,
      filepathOffset: Int,
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends TransformEventResponse {

    override def write(_oprot: TProtocol): Unit = {
      _oprot match {
        case i: LazyTProtocol => i.writeRaw(_buf, _start_offset, _end_offset - _start_offset)
        case _ => super.write(_oprot)
      }
    }

    lazy val filepath: String =
      if (filepathOffset == -1)
        null
      else {
        _proto.decodeString(_buf, filepathOffset)
      }

    /**
     * Override the super hash code to make it a lazy val rather than def.
     *
     * Calculating the hash code can be expensive, caching it where possible
     * can provide significant performance wins. (Key in a hash map for instance)
     * Usually not safe since the normal constructor will accept a mutable map or
     * set as an arg
     * Here however we control how the class is generated from serialized data.
     * With the class private and the contract that we throw away our mutable references
     * having the hash code lazy here is safe.
     */
    override lazy val hashCode = super.hashCode
  }

  /**
   * This Proxy trait allows you to extend the TransformEventResponse trait with additional state or
   * behavior and implement the read-only methods from TransformEventResponse using an underlying
   * instance.
   */
  trait Proxy extends TransformEventResponse {
    protected def _underlying_TransformEventResponse: TransformEventResponse
    override def oldDataFrameId: Int = _underlying_TransformEventResponse.oldDataFrameId
    override def newDataFrameId: Int = _underlying_TransformEventResponse.newDataFrameId
    override def transformerId: Int = _underlying_TransformEventResponse.transformerId
    override def eventId: Int = _underlying_TransformEventResponse.eventId
    override def filepath: String = _underlying_TransformEventResponse.filepath
    override def _passthroughFields: immutable$Map[Short, TFieldBlob] = _underlying_TransformEventResponse._passthroughFields
  }
}

/**
 * Prefer the companion object's [[modeldb.TransformEventResponse.apply]]
 * for construction if you don't need to specify passthrough fields.
 */
trait TransformEventResponse
  extends ThriftStruct
  with _root_.scala.Product5[Int, Int, Int, Int, String]
  with ValidatingThriftStruct[TransformEventResponse]
  with java.io.Serializable
{
  import TransformEventResponse._

  def oldDataFrameId: Int
  def newDataFrameId: Int
  def transformerId: Int
  def eventId: Int
  def filepath: String

  def _passthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty

  def _1: Int = oldDataFrameId
  def _2: Int = newDataFrameId
  def _3: Int = transformerId
  def _4: Int = eventId
  def _5: String = filepath

  def toTuple: _root_.scala.Tuple5[Int, Int, Int, Int, String] = {
    (
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath
    )
  }


  /**
   * Gets a field value encoded as a binary blob using TCompactProtocol.  If the specified field
   * is present in the passthrough map, that value is returned.  Otherwise, if the specified field
   * is known and not optional and set to None, then the field is serialized and returned.
   */
  def getFieldBlob(_fieldId: Short): _root_.scala.Option[TFieldBlob] = {
    lazy val _buff = new TMemoryBuffer(32)
    lazy val _oprot = new TCompactProtocol(_buff)
    _passthroughFields.get(_fieldId) match {
      case blob: _root_.scala.Some[TFieldBlob] => blob
      case _root_.scala.None => {
        val _fieldOpt: _root_.scala.Option[TField] =
          _fieldId match {
            case 1 =>
              if (true) {
                writeOldDataFrameIdValue(oldDataFrameId, _oprot)
                _root_.scala.Some(TransformEventResponse.OldDataFrameIdField)
              } else {
                _root_.scala.None
              }
            case 2 =>
              if (true) {
                writeNewDataFrameIdValue(newDataFrameId, _oprot)
                _root_.scala.Some(TransformEventResponse.NewDataFrameIdField)
              } else {
                _root_.scala.None
              }
            case 3 =>
              if (true) {
                writeTransformerIdValue(transformerId, _oprot)
                _root_.scala.Some(TransformEventResponse.TransformerIdField)
              } else {
                _root_.scala.None
              }
            case 4 =>
              if (true) {
                writeEventIdValue(eventId, _oprot)
                _root_.scala.Some(TransformEventResponse.EventIdField)
              } else {
                _root_.scala.None
              }
            case 5 =>
              if (filepath ne null) {
                writeFilepathValue(filepath, _oprot)
                _root_.scala.Some(TransformEventResponse.FilepathField)
              } else {
                _root_.scala.None
              }
            case _ => _root_.scala.None
          }
        _fieldOpt match {
          case _root_.scala.Some(_field) =>
            _root_.scala.Some(TFieldBlob(_field, Buf.ByteArray.Owned(_buff.getArray())))
          case _root_.scala.None =>
            _root_.scala.None
        }
      }
    }
  }

  /**
   * Collects TCompactProtocol-encoded field values according to `getFieldBlob` into a map.
   */
  def getFieldBlobs(ids: TraversableOnce[Short]): immutable$Map[Short, TFieldBlob] =
    (ids flatMap { id => getFieldBlob(id) map { id -> _ } }).toMap

  /**
   * Sets a field using a TCompactProtocol-encoded binary blob.  If the field is a known
   * field, the blob is decoded and the field is set to the decoded value.  If the field
   * is unknown and passthrough fields are enabled, then the blob will be stored in
   * _passthroughFields.
   */
  def setField(_blob: TFieldBlob): TransformEventResponse = {
    var oldDataFrameId: Int = this.oldDataFrameId
    var newDataFrameId: Int = this.newDataFrameId
    var transformerId: Int = this.transformerId
    var eventId: Int = this.eventId
    var filepath: String = this.filepath
    var _passthroughFields = this._passthroughFields
    _blob.id match {
      case 1 =>
        oldDataFrameId = readOldDataFrameIdValue(_blob.read)
      case 2 =>
        newDataFrameId = readNewDataFrameIdValue(_blob.read)
      case 3 =>
        transformerId = readTransformerIdValue(_blob.read)
      case 4 =>
        eventId = readEventIdValue(_blob.read)
      case 5 =>
        filepath = readFilepathValue(_blob.read)
      case _ => _passthroughFields += (_blob.id -> _blob)
    }
    new Immutable(
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath,
      _passthroughFields
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetField(_fieldId: Short): TransformEventResponse = {
    var oldDataFrameId: Int = this.oldDataFrameId
    var newDataFrameId: Int = this.newDataFrameId
    var transformerId: Int = this.transformerId
    var eventId: Int = this.eventId
    var filepath: String = this.filepath

    _fieldId match {
      case 1 =>
        oldDataFrameId = 0
      case 2 =>
        newDataFrameId = 0
      case 3 =>
        transformerId = 0
      case 4 =>
        eventId = 0
      case 5 =>
        filepath = null
      case _ =>
    }
    new Immutable(
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath,
      _passthroughFields - _fieldId
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetOldDataFrameId: TransformEventResponse = unsetField(1)

  def unsetNewDataFrameId: TransformEventResponse = unsetField(2)

  def unsetTransformerId: TransformEventResponse = unsetField(3)

  def unsetEventId: TransformEventResponse = unsetField(4)

  def unsetFilepath: TransformEventResponse = unsetField(5)


  override def write(_oprot: TProtocol): Unit = {
    TransformEventResponse.validate(this)
    _oprot.writeStructBegin(Struct)
    writeOldDataFrameIdField(oldDataFrameId, _oprot)
    writeNewDataFrameIdField(newDataFrameId, _oprot)
    writeTransformerIdField(transformerId, _oprot)
    writeEventIdField(eventId, _oprot)
    if (filepath ne null) writeFilepathField(filepath, _oprot)
    if (_passthroughFields.nonEmpty) {
      _passthroughFields.values.foreach { _.write(_oprot) }
    }
    _oprot.writeFieldStop()
    _oprot.writeStructEnd()
  }

  def copy(
    oldDataFrameId: Int = this.oldDataFrameId,
    newDataFrameId: Int = this.newDataFrameId,
    transformerId: Int = this.transformerId,
    eventId: Int = this.eventId,
    filepath: String = this.filepath,
    _passthroughFields: immutable$Map[Short, TFieldBlob] = this._passthroughFields
  ): TransformEventResponse =
    new Immutable(
      oldDataFrameId,
      newDataFrameId,
      transformerId,
      eventId,
      filepath,
      _passthroughFields
    )

  override def canEqual(other: Any): Boolean = other.isInstanceOf[TransformEventResponse]

  private def _equals(x: TransformEventResponse, y: TransformEventResponse): Boolean =
      x.productArity == y.productArity &&
      x.productIterator.sameElements(y.productIterator) &&
      x._passthroughFields == y._passthroughFields

  override def equals(other: Any): Boolean =
    canEqual(other) &&
      _equals(this, other.asInstanceOf[TransformEventResponse])

  override def hashCode: Int = {
    var hash = _root_.scala.runtime.ScalaRunTime._hashCode(this)
    hash
  }

  override def toString: String = _root_.scala.runtime.ScalaRunTime._toString(this)


  override def productArity: Int = 5

  override def productElement(n: Int): Any = n match {
    case 0 => this.oldDataFrameId
    case 1 => this.newDataFrameId
    case 2 => this.transformerId
    case 3 => this.eventId
    case 4 => this.filepath
    case _ => throw new IndexOutOfBoundsException(n.toString)
  }

  override def productPrefix: String = "TransformEventResponse"

  def _codec: ValidatingThriftStructCodec3[TransformEventResponse] = TransformEventResponse
}

