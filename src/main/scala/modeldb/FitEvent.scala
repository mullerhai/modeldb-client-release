/**
 * Generated by Scrooge
 *   version: 18.10.0
 *   rev: dda071e1412b53f4bfdebc19e474f584e475d475
 *   built at: 20181018-174244
 */
package modeldb

import com.twitter.io.Buf
import com.twitter.scrooge.{
  LazyTProtocol,
  TFieldBlob,
  ThriftException,
  ThriftStruct,
  ThriftStructCodec3,
  ThriftStructFieldInfo,
  ThriftStructMetaData,
  ThriftUtil,
  ValidatingThriftStruct,
  ValidatingThriftStructCodec3
}
import org.apache.thrift.protocol._
import org.apache.thrift.transport.{TMemoryBuffer, TTransport, TIOStreamTransport}
import java.io.ByteArrayInputStream
import java.nio.ByteBuffer
import java.util.Arrays
import java.util.concurrent.atomic.AtomicInteger
import scala.collection.immutable.{Map => immutable$Map}
import scala.collection.mutable.Builder
import scala.collection.mutable.{
  ArrayBuffer => mutable$ArrayBuffer, Buffer => mutable$Buffer,
  HashMap => mutable$HashMap, HashSet => mutable$HashSet}
import scala.collection.{Map, Set}


object FitEvent extends ValidatingThriftStructCodec3[FitEvent] {
  val NoPassthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty[Short, TFieldBlob]
  val Struct: TStruct = new TStruct("FitEvent")
  val DfField: TField = new TField("df", TType.STRUCT, 1)
  val DfFieldManifest: Manifest[modeldb.DataFrame] = implicitly[Manifest[modeldb.DataFrame]]
  val SpecField: TField = new TField("spec", TType.STRUCT, 2)
  val SpecFieldManifest: Manifest[modeldb.TransformerSpec] = implicitly[Manifest[modeldb.TransformerSpec]]
  val ModelField: TField = new TField("model", TType.STRUCT, 3)
  val ModelFieldManifest: Manifest[modeldb.Transformer] = implicitly[Manifest[modeldb.Transformer]]
  val FeatureColumnsField: TField = new TField("featureColumns", TType.LIST, 4)
  val FeatureColumnsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val PredictionColumnsField: TField = new TField("predictionColumns", TType.LIST, 5)
  val PredictionColumnsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val LabelColumnsField: TField = new TField("labelColumns", TType.LIST, 6)
  val LabelColumnsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val ExperimentRunIdField: TField = new TField("experimentRunId", TType.I32, 7)
  val ExperimentRunIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val ProblemTypeField: TField = new TField("problemType", TType.ENUM, 8)
  val ProblemTypeFieldI32: TField = new TField("problemType", TType.I32, 8)
  val ProblemTypeFieldManifest: Manifest[modeldb.ProblemType] = implicitly[Manifest[modeldb.ProblemType]]
  val MetadataField: TField = new TField("metadata", TType.STRING, 9)
  val MetadataFieldManifest: Manifest[String] = implicitly[Manifest[String]]

  /**
   * Field information in declaration order.
   */
  lazy val fieldInfos: scala.List[ThriftStructFieldInfo] = scala.List[ThriftStructFieldInfo](
    new ThriftStructFieldInfo(
      DfField,
      false,
      false,
      DfFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      SpecField,
      false,
      false,
      SpecFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ModelField,
      false,
      false,
      ModelFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      FeatureColumnsField,
      false,
      false,
      FeatureColumnsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      PredictionColumnsField,
      false,
      false,
      PredictionColumnsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      LabelColumnsField,
      false,
      false,
      LabelColumnsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ExperimentRunIdField,
      false,
      false,
      ExperimentRunIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ProblemTypeField,
      false,
      false,
      ProblemTypeFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      Some[modeldb.ProblemType](ProblemType.Undefined)
    ),
    new ThriftStructFieldInfo(
      MetadataField,
      true,
      false,
      MetadataFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    )
  )

  lazy val structAnnotations: immutable$Map[String, String] =
    immutable$Map.empty[String, String]

  /**
   * Checks that all required fields are non-null.
   */
  def validate(_item: FitEvent): Unit = {
  }

  /**
   * Checks that the struct is a valid as a new instance. If there are any missing required or
   * construction required fields, return a non-empty list.
   */
  def validateNewInstance(item: FitEvent): scala.Seq[com.twitter.scrooge.validation.Issue] = {
    val buf = scala.collection.mutable.ListBuffer.empty[com.twitter.scrooge.validation.Issue]

    buf ++= validateField(item.df)
    buf ++= validateField(item.spec)
    buf ++= validateField(item.model)
    buf ++= validateField(item.featureColumns)
    buf ++= validateField(item.predictionColumns)
    buf ++= validateField(item.labelColumns)
    buf ++= validateField(item.experimentRunId)
    buf ++= validateField(item.problemType)
    buf ++= validateField(item.metadata)
    buf.toList
  }

  def withoutPassthroughFields(original: FitEvent): FitEvent =
    new Immutable(
      df =
        {
          val field = original.df
          modeldb.DataFrame.withoutPassthroughFields(field)
        },
      spec =
        {
          val field = original.spec
          modeldb.TransformerSpec.withoutPassthroughFields(field)
        },
      model =
        {
          val field = original.model
          modeldb.Transformer.withoutPassthroughFields(field)
        },
      featureColumns =
        {
          val field = original.featureColumns
          field.map { field =>
            field
          }
        },
      predictionColumns =
        {
          val field = original.predictionColumns
          field.map { field =>
            field
          }
        },
      labelColumns =
        {
          val field = original.labelColumns
          field.map { field =>
            field
          }
        },
      experimentRunId =
        {
          val field = original.experimentRunId
          field
        },
      problemType =
        {
          val field = original.problemType
          field
        },
      metadata =
        {
          val field = original.metadata
          field.map { field =>
            field
          }
        }
    )

  override def encode(_item: FitEvent, _oproto: TProtocol): Unit = {
    _item.write(_oproto)
  }


  private[this] def lazyDecode(_iprot: LazyTProtocol): FitEvent = {

    var df: modeldb.DataFrame = null
    var spec: modeldb.TransformerSpec = null
    var model: modeldb.Transformer = null
    var featureColumns: Seq[String] = Seq[String]()
    var predictionColumns: Seq[String] = Seq[String]()
    var labelColumns: Seq[String] = Seq[String]()
    var experimentRunId: Int = 0
    var problemType: modeldb.ProblemType = ProblemType.Undefined
    var metadataOffset: Int = -1

    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false
    val _start_offset = _iprot.offset

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                df = readDfValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'df' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                spec = readSpecValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'spec' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                model = readModelValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'model' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.LIST =>
    
                featureColumns = readFeatureColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'featureColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.LIST =>
    
                predictionColumns = readPredictionColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'predictionColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 6 =>
            _field.`type` match {
              case TType.LIST =>
    
                labelColumns = readLabelColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'labelColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 7 =>
            _field.`type` match {
              case TType.I32 =>
    
                experimentRunId = readExperimentRunIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'experimentRunId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 8 =>
            _field.`type` match {
              case TType.I32 | TType.ENUM =>
    
                problemType = readProblemTypeValue(_iprot)
              case _actualType =>
                val _expectedType = TType.ENUM
                throw new TProtocolException(
                  "Received wrong type for field 'problemType' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 9 =>
            _field.`type` match {
              case TType.STRING =>
                metadataOffset = _iprot.offsetSkipString
    
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'metadata' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    new LazyImmutable(
      _iprot,
      _iprot.buffer,
      _start_offset,
      _iprot.offset,
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadataOffset,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  override def decode(_iprot: TProtocol): FitEvent =
    _iprot match {
      case i: LazyTProtocol => lazyDecode(i)
      case i => eagerDecode(i)
    }

  private[modeldb] def eagerDecode(_iprot: TProtocol): FitEvent = {
    var df: modeldb.DataFrame = null
    var spec: modeldb.TransformerSpec = null
    var model: modeldb.Transformer = null
    var featureColumns: Seq[String] = Seq[String]()
    var predictionColumns: Seq[String] = Seq[String]()
    var labelColumns: Seq[String] = Seq[String]()
    var experimentRunId: Int = 0
    var problemType: modeldb.ProblemType = ProblemType.Undefined
    var metadata: _root_.scala.Option[String] = _root_.scala.None
    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.STRUCT =>
                df = readDfValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'df' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.STRUCT =>
                spec = readSpecValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'spec' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.STRUCT =>
                model = readModelValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'model' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.LIST =>
                featureColumns = readFeatureColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'featureColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.LIST =>
                predictionColumns = readPredictionColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'predictionColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 6 =>
            _field.`type` match {
              case TType.LIST =>
                labelColumns = readLabelColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'labelColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 7 =>
            _field.`type` match {
              case TType.I32 =>
                experimentRunId = readExperimentRunIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'experimentRunId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 8 =>
            _field.`type` match {
              case TType.I32 | TType.ENUM =>
                problemType = readProblemTypeValue(_iprot)
              case _actualType =>
                val _expectedType = TType.ENUM
                throw new TProtocolException(
                  "Received wrong type for field 'problemType' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 9 =>
            _field.`type` match {
              case TType.STRING =>
                metadata = _root_.scala.Some(readMetadataValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'metadata' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    new Immutable(
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  def apply(
    df: modeldb.DataFrame,
    spec: modeldb.TransformerSpec,
    model: modeldb.Transformer,
    featureColumns: Seq[String] = Seq[String](),
    predictionColumns: Seq[String] = Seq[String](),
    labelColumns: Seq[String] = Seq[String](),
    experimentRunId: Int,
    problemType: modeldb.ProblemType = ProblemType.Undefined,
    metadata: _root_.scala.Option[String] = _root_.scala.None
  ): FitEvent =
    new Immutable(
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata
    )

  def unapply(_item: FitEvent): _root_.scala.Option[_root_.scala.Tuple9[modeldb.DataFrame, modeldb.TransformerSpec, modeldb.Transformer, Seq[String], Seq[String], Seq[String], Int, modeldb.ProblemType, Option[String]]] = _root_.scala.Some(_item.toTuple)


  @inline private[modeldb] def readDfValue(_iprot: TProtocol): modeldb.DataFrame = {
    modeldb.DataFrame.decode(_iprot)
  }

  @inline private def writeDfField(df_item: modeldb.DataFrame, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(DfField)
    writeDfValue(df_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeDfValue(df_item: modeldb.DataFrame, _oprot: TProtocol): Unit = {
    df_item.write(_oprot)
  }

  @inline private[modeldb] def readSpecValue(_iprot: TProtocol): modeldb.TransformerSpec = {
    modeldb.TransformerSpec.decode(_iprot)
  }

  @inline private def writeSpecField(spec_item: modeldb.TransformerSpec, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(SpecField)
    writeSpecValue(spec_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeSpecValue(spec_item: modeldb.TransformerSpec, _oprot: TProtocol): Unit = {
    spec_item.write(_oprot)
  }

  @inline private[modeldb] def readModelValue(_iprot: TProtocol): modeldb.Transformer = {
    modeldb.Transformer.decode(_iprot)
  }

  @inline private def writeModelField(model_item: modeldb.Transformer, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ModelField)
    writeModelValue(model_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeModelValue(model_item: modeldb.Transformer, _oprot: TProtocol): Unit = {
    model_item.write(_oprot)
  }

  @inline private[modeldb] def readFeatureColumnsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writeFeatureColumnsField(featureColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(FeatureColumnsField)
    writeFeatureColumnsValue(featureColumns_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeFeatureColumnsValue(featureColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, featureColumns_item.size))
    featureColumns_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = featureColumns_item.size
        while (_i < _size) {
          val featureColumns_item_element = featureColumns_item(_i)
          _oprot.writeString(featureColumns_item_element)
          _i += 1
        }
      case _ =>
        featureColumns_item.foreach { featureColumns_item_element =>
          _oprot.writeString(featureColumns_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readPredictionColumnsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writePredictionColumnsField(predictionColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(PredictionColumnsField)
    writePredictionColumnsValue(predictionColumns_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writePredictionColumnsValue(predictionColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, predictionColumns_item.size))
    predictionColumns_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = predictionColumns_item.size
        while (_i < _size) {
          val predictionColumns_item_element = predictionColumns_item(_i)
          _oprot.writeString(predictionColumns_item_element)
          _i += 1
        }
      case _ =>
        predictionColumns_item.foreach { predictionColumns_item_element =>
          _oprot.writeString(predictionColumns_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readLabelColumnsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writeLabelColumnsField(labelColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(LabelColumnsField)
    writeLabelColumnsValue(labelColumns_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeLabelColumnsValue(labelColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, labelColumns_item.size))
    labelColumns_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = labelColumns_item.size
        while (_i < _size) {
          val labelColumns_item_element = labelColumns_item(_i)
          _oprot.writeString(labelColumns_item_element)
          _i += 1
        }
      case _ =>
        labelColumns_item.foreach { labelColumns_item_element =>
          _oprot.writeString(labelColumns_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readExperimentRunIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeExperimentRunIdField(experimentRunId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ExperimentRunIdField)
    writeExperimentRunIdValue(experimentRunId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeExperimentRunIdValue(experimentRunId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(experimentRunId_item)
  }

  @inline private[modeldb] def readProblemTypeValue(_iprot: TProtocol): modeldb.ProblemType = {
    modeldb.ProblemType.getOrUnknown(_iprot.readI32())
  }

  @inline private def writeProblemTypeField(problemType_item: modeldb.ProblemType, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ProblemTypeFieldI32)
    writeProblemTypeValue(problemType_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeProblemTypeValue(problemType_item: modeldb.ProblemType, _oprot: TProtocol): Unit = {
    _oprot.writeI32(problemType_item.value)
  }

  @inline private[modeldb] def readMetadataValue(_iprot: TProtocol): String = {
    _iprot.readString()
  }

  @inline private def writeMetadataField(metadata_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(MetadataField)
    writeMetadataValue(metadata_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeMetadataValue(metadata_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeString(metadata_item)
  }


  object Immutable extends ThriftStructCodec3[FitEvent] {
    override def encode(_item: FitEvent, _oproto: TProtocol): Unit = { _item.write(_oproto) }
    override def decode(_iprot: TProtocol): FitEvent = FitEvent.decode(_iprot)
    override lazy val metaData: ThriftStructMetaData[FitEvent] = FitEvent.metaData
  }

  /**
   * The default read-only implementation of FitEvent.  You typically should not need to
   * directly reference this class; instead, use the FitEvent.apply method to construct
   * new instances.
   */
  class Immutable(
      val df: modeldb.DataFrame,
      val spec: modeldb.TransformerSpec,
      val model: modeldb.Transformer,
      val featureColumns: Seq[String],
      val predictionColumns: Seq[String],
      val labelColumns: Seq[String],
      val experimentRunId: Int,
      val problemType: modeldb.ProblemType,
      val metadata: _root_.scala.Option[String],
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends FitEvent {
    def this(
      df: modeldb.DataFrame,
      spec: modeldb.TransformerSpec,
      model: modeldb.Transformer,
      featureColumns: Seq[String] = Seq[String](),
      predictionColumns: Seq[String] = Seq[String](),
      labelColumns: Seq[String] = Seq[String](),
      experimentRunId: Int,
      problemType: modeldb.ProblemType = ProblemType.Undefined,
      metadata: _root_.scala.Option[String] = _root_.scala.None
    ) = this(
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata,
      Map.empty[Short, TFieldBlob]
    )
  }

  /**
   * This is another Immutable, this however keeps strings as lazy values that are lazily decoded from the backing
   * array byte on read.
   */
  private[this] class LazyImmutable(
      _proto: LazyTProtocol,
      _buf: Array[Byte],
      _start_offset: Int,
      _end_offset: Int,
      val df: modeldb.DataFrame,
      val spec: modeldb.TransformerSpec,
      val model: modeldb.Transformer,
      val featureColumns: Seq[String],
      val predictionColumns: Seq[String],
      val labelColumns: Seq[String],
      val experimentRunId: Int,
      val problemType: modeldb.ProblemType,
      metadataOffset: Int,
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends FitEvent {

    override def write(_oprot: TProtocol): Unit = {
      _oprot match {
        case i: LazyTProtocol => i.writeRaw(_buf, _start_offset, _end_offset - _start_offset)
        case _ => super.write(_oprot)
      }
    }

    lazy val metadata: _root_.scala.Option[String] =
      if (metadataOffset == -1)
        None
      else {
        Some(_proto.decodeString(_buf, metadataOffset))
      }

    /**
     * Override the super hash code to make it a lazy val rather than def.
     *
     * Calculating the hash code can be expensive, caching it where possible
     * can provide significant performance wins. (Key in a hash map for instance)
     * Usually not safe since the normal constructor will accept a mutable map or
     * set as an arg
     * Here however we control how the class is generated from serialized data.
     * With the class private and the contract that we throw away our mutable references
     * having the hash code lazy here is safe.
     */
    override lazy val hashCode = super.hashCode
  }

  /**
   * This Proxy trait allows you to extend the FitEvent trait with additional state or
   * behavior and implement the read-only methods from FitEvent using an underlying
   * instance.
   */
  trait Proxy extends FitEvent {
    protected def _underlying_FitEvent: FitEvent
    override def df: modeldb.DataFrame = _underlying_FitEvent.df
    override def spec: modeldb.TransformerSpec = _underlying_FitEvent.spec
    override def model: modeldb.Transformer = _underlying_FitEvent.model
    override def featureColumns: Seq[String] = _underlying_FitEvent.featureColumns
    override def predictionColumns: Seq[String] = _underlying_FitEvent.predictionColumns
    override def labelColumns: Seq[String] = _underlying_FitEvent.labelColumns
    override def experimentRunId: Int = _underlying_FitEvent.experimentRunId
    override def problemType: modeldb.ProblemType = _underlying_FitEvent.problemType
    override def metadata: _root_.scala.Option[String] = _underlying_FitEvent.metadata
    override def _passthroughFields: immutable$Map[Short, TFieldBlob] = _underlying_FitEvent._passthroughFields
  }
}

/**
 * Prefer the companion object's [[modeldb.FitEvent.apply]]
 * for construction if you don't need to specify passthrough fields.
 */
trait FitEvent
  extends ThriftStruct
  with _root_.scala.Product9[modeldb.DataFrame, modeldb.TransformerSpec, modeldb.Transformer, Seq[String], Seq[String], Seq[String], Int, modeldb.ProblemType, Option[String]]
  with ValidatingThriftStruct[FitEvent]
  with java.io.Serializable
{
  import FitEvent._

  def df: modeldb.DataFrame
  def spec: modeldb.TransformerSpec
  def model: modeldb.Transformer
  def featureColumns: Seq[String]
  def predictionColumns: Seq[String]
  def labelColumns: Seq[String]
  def experimentRunId: Int
  def problemType: modeldb.ProblemType
  def metadata: _root_.scala.Option[String]

  def _passthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty

  def _1: modeldb.DataFrame = df
  def _2: modeldb.TransformerSpec = spec
  def _3: modeldb.Transformer = model
  def _4: Seq[String] = featureColumns
  def _5: Seq[String] = predictionColumns
  def _6: Seq[String] = labelColumns
  def _7: Int = experimentRunId
  def _8: modeldb.ProblemType = problemType
  def _9: _root_.scala.Option[String] = metadata

  def toTuple: _root_.scala.Tuple9[modeldb.DataFrame, modeldb.TransformerSpec, modeldb.Transformer, Seq[String], Seq[String], Seq[String], Int, modeldb.ProblemType, Option[String]] = {
    (
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata
    )
  }


  /**
   * Gets a field value encoded as a binary blob using TCompactProtocol.  If the specified field
   * is present in the passthrough map, that value is returned.  Otherwise, if the specified field
   * is known and not optional and set to None, then the field is serialized and returned.
   */
  def getFieldBlob(_fieldId: Short): _root_.scala.Option[TFieldBlob] = {
    lazy val _buff = new TMemoryBuffer(32)
    lazy val _oprot = new TCompactProtocol(_buff)
    _passthroughFields.get(_fieldId) match {
      case blob: _root_.scala.Some[TFieldBlob] => blob
      case _root_.scala.None => {
        val _fieldOpt: _root_.scala.Option[TField] =
          _fieldId match {
            case 1 =>
              if (df ne null) {
                writeDfValue(df, _oprot)
                _root_.scala.Some(FitEvent.DfField)
              } else {
                _root_.scala.None
              }
            case 2 =>
              if (spec ne null) {
                writeSpecValue(spec, _oprot)
                _root_.scala.Some(FitEvent.SpecField)
              } else {
                _root_.scala.None
              }
            case 3 =>
              if (model ne null) {
                writeModelValue(model, _oprot)
                _root_.scala.Some(FitEvent.ModelField)
              } else {
                _root_.scala.None
              }
            case 4 =>
              if (featureColumns ne null) {
                writeFeatureColumnsValue(featureColumns, _oprot)
                _root_.scala.Some(FitEvent.FeatureColumnsField)
              } else {
                _root_.scala.None
              }
            case 5 =>
              if (predictionColumns ne null) {
                writePredictionColumnsValue(predictionColumns, _oprot)
                _root_.scala.Some(FitEvent.PredictionColumnsField)
              } else {
                _root_.scala.None
              }
            case 6 =>
              if (labelColumns ne null) {
                writeLabelColumnsValue(labelColumns, _oprot)
                _root_.scala.Some(FitEvent.LabelColumnsField)
              } else {
                _root_.scala.None
              }
            case 7 =>
              if (true) {
                writeExperimentRunIdValue(experimentRunId, _oprot)
                _root_.scala.Some(FitEvent.ExperimentRunIdField)
              } else {
                _root_.scala.None
              }
            case 8 =>
              if (problemType ne null) {
                writeProblemTypeValue(problemType, _oprot)
                _root_.scala.Some(FitEvent.ProblemTypeField)
              } else {
                _root_.scala.None
              }
            case 9 =>
              if (metadata.isDefined) {
                writeMetadataValue(metadata.get, _oprot)
                _root_.scala.Some(FitEvent.MetadataField)
              } else {
                _root_.scala.None
              }
            case _ => _root_.scala.None
          }
        _fieldOpt match {
          case _root_.scala.Some(_field) =>
            _root_.scala.Some(TFieldBlob(_field, Buf.ByteArray.Owned(_buff.getArray())))
          case _root_.scala.None =>
            _root_.scala.None
        }
      }
    }
  }

  /**
   * Collects TCompactProtocol-encoded field values according to `getFieldBlob` into a map.
   */
  def getFieldBlobs(ids: TraversableOnce[Short]): immutable$Map[Short, TFieldBlob] =
    (ids flatMap { id => getFieldBlob(id) map { id -> _ } }).toMap

  /**
   * Sets a field using a TCompactProtocol-encoded binary blob.  If the field is a known
   * field, the blob is decoded and the field is set to the decoded value.  If the field
   * is unknown and passthrough fields are enabled, then the blob will be stored in
   * _passthroughFields.
   */
  def setField(_blob: TFieldBlob): FitEvent = {
    var df: modeldb.DataFrame = this.df
    var spec: modeldb.TransformerSpec = this.spec
    var model: modeldb.Transformer = this.model
    var featureColumns: Seq[String] = this.featureColumns
    var predictionColumns: Seq[String] = this.predictionColumns
    var labelColumns: Seq[String] = this.labelColumns
    var experimentRunId: Int = this.experimentRunId
    var problemType: modeldb.ProblemType = this.problemType
    var metadata: _root_.scala.Option[String] = this.metadata
    var _passthroughFields = this._passthroughFields
    _blob.id match {
      case 1 =>
        df = readDfValue(_blob.read)
      case 2 =>
        spec = readSpecValue(_blob.read)
      case 3 =>
        model = readModelValue(_blob.read)
      case 4 =>
        featureColumns = readFeatureColumnsValue(_blob.read)
      case 5 =>
        predictionColumns = readPredictionColumnsValue(_blob.read)
      case 6 =>
        labelColumns = readLabelColumnsValue(_blob.read)
      case 7 =>
        experimentRunId = readExperimentRunIdValue(_blob.read)
      case 8 =>
        problemType = readProblemTypeValue(_blob.read)
      case 9 =>
        metadata = _root_.scala.Some(readMetadataValue(_blob.read))
      case _ => _passthroughFields += (_blob.id -> _blob)
    }
    new Immutable(
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata,
      _passthroughFields
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetField(_fieldId: Short): FitEvent = {
    var df: modeldb.DataFrame = this.df
    var spec: modeldb.TransformerSpec = this.spec
    var model: modeldb.Transformer = this.model
    var featureColumns: Seq[String] = this.featureColumns
    var predictionColumns: Seq[String] = this.predictionColumns
    var labelColumns: Seq[String] = this.labelColumns
    var experimentRunId: Int = this.experimentRunId
    var problemType: modeldb.ProblemType = this.problemType
    var metadata: _root_.scala.Option[String] = this.metadata

    _fieldId match {
      case 1 =>
        df = null
      case 2 =>
        spec = null
      case 3 =>
        model = null
      case 4 =>
        featureColumns = Seq[String]()
      case 5 =>
        predictionColumns = Seq[String]()
      case 6 =>
        labelColumns = Seq[String]()
      case 7 =>
        experimentRunId = 0
      case 8 =>
        problemType = ProblemType.Undefined
      case 9 =>
        metadata = _root_.scala.None
      case _ =>
    }
    new Immutable(
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata,
      _passthroughFields - _fieldId
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetDf: FitEvent = unsetField(1)

  def unsetSpec: FitEvent = unsetField(2)

  def unsetModel: FitEvent = unsetField(3)

  def unsetFeatureColumns: FitEvent = unsetField(4)

  def unsetPredictionColumns: FitEvent = unsetField(5)

  def unsetLabelColumns: FitEvent = unsetField(6)

  def unsetExperimentRunId: FitEvent = unsetField(7)

  def unsetProblemType: FitEvent = unsetField(8)

  def unsetMetadata: FitEvent = unsetField(9)


  override def write(_oprot: TProtocol): Unit = {
    FitEvent.validate(this)
    _oprot.writeStructBegin(Struct)
    if (df ne null) writeDfField(df, _oprot)
    if (spec ne null) writeSpecField(spec, _oprot)
    if (model ne null) writeModelField(model, _oprot)
    if (featureColumns ne null) writeFeatureColumnsField(featureColumns, _oprot)
    if (predictionColumns ne null) writePredictionColumnsField(predictionColumns, _oprot)
    if (labelColumns ne null) writeLabelColumnsField(labelColumns, _oprot)
    writeExperimentRunIdField(experimentRunId, _oprot)
    if (problemType ne null) writeProblemTypeField(problemType, _oprot)
    if (metadata.isDefined) writeMetadataField(metadata.get, _oprot)
    if (_passthroughFields.nonEmpty) {
      _passthroughFields.values.foreach { _.write(_oprot) }
    }
    _oprot.writeFieldStop()
    _oprot.writeStructEnd()
  }

  def copy(
    df: modeldb.DataFrame = this.df,
    spec: modeldb.TransformerSpec = this.spec,
    model: modeldb.Transformer = this.model,
    featureColumns: Seq[String] = this.featureColumns,
    predictionColumns: Seq[String] = this.predictionColumns,
    labelColumns: Seq[String] = this.labelColumns,
    experimentRunId: Int = this.experimentRunId,
    problemType: modeldb.ProblemType = this.problemType,
    metadata: _root_.scala.Option[String] = this.metadata,
    _passthroughFields: immutable$Map[Short, TFieldBlob] = this._passthroughFields
  ): FitEvent =
    new Immutable(
      df,
      spec,
      model,
      featureColumns,
      predictionColumns,
      labelColumns,
      experimentRunId,
      problemType,
      metadata,
      _passthroughFields
    )

  override def canEqual(other: Any): Boolean = other.isInstanceOf[FitEvent]

  private def _equals(x: FitEvent, y: FitEvent): Boolean =
      x.productArity == y.productArity &&
      x.productIterator.sameElements(y.productIterator) &&
      x._passthroughFields == y._passthroughFields

  override def equals(other: Any): Boolean =
    canEqual(other) &&
      _equals(this, other.asInstanceOf[FitEvent])

  override def hashCode: Int = {
    var hash = _root_.scala.runtime.ScalaRunTime._hashCode(this)
    hash
  }

  override def toString: String = _root_.scala.runtime.ScalaRunTime._toString(this)


  override def productArity: Int = 9

  override def productElement(n: Int): Any = n match {
    case 0 => this.df
    case 1 => this.spec
    case 2 => this.model
    case 3 => this.featureColumns
    case 4 => this.predictionColumns
    case 5 => this.labelColumns
    case 6 => this.experimentRunId
    case 7 => this.problemType
    case 8 => this.metadata
    case _ => throw new IndexOutOfBoundsException(n.toString)
  }

  override def productPrefix: String = "FitEvent"

  def _codec: ValidatingThriftStructCodec3[FitEvent] = FitEvent
}

