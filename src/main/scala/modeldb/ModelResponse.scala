/**
 * Generated by Scrooge
 *   version: 18.10.0
 *   rev: dda071e1412b53f4bfdebc19e474f584e475d475
 *   built at: 20181018-174244
 */
package modeldb

import com.twitter.io.Buf
import com.twitter.scrooge.{
  LazyTProtocol,
  TFieldBlob,
  ThriftException,
  ThriftStruct,
  ThriftStructCodec3,
  ThriftStructFieldInfo,
  ThriftStructMetaData,
  ThriftUtil,
  ValidatingThriftStruct,
  ValidatingThriftStructCodec3
}
import org.apache.thrift.protocol._
import org.apache.thrift.transport.{TMemoryBuffer, TTransport, TIOStreamTransport}
import java.io.ByteArrayInputStream
import java.nio.ByteBuffer
import java.util.Arrays
import java.util.concurrent.atomic.AtomicInteger
import scala.collection.immutable.{Map => immutable$Map}
import scala.collection.mutable.Builder
import scala.collection.mutable.{
  ArrayBuffer => mutable$ArrayBuffer, Buffer => mutable$Buffer,
  HashMap => mutable$HashMap, HashSet => mutable$HashSet}
import scala.collection.{Map, Set}


object ModelResponse extends ValidatingThriftStructCodec3[ModelResponse] {
  val NoPassthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty[Short, TFieldBlob]
  val Struct: TStruct = new TStruct("ModelResponse")
  val IdField: TField = new TField("id", TType.I32, 1)
  val IdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val ExperimentRunIdField: TField = new TField("experimentRunId", TType.I32, 2)
  val ExperimentRunIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val ExperimentIdField: TField = new TField("experimentId", TType.I32, 3)
  val ExperimentIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val ProjectIdField: TField = new TField("projectId", TType.I32, 4)
  val ProjectIdFieldManifest: Manifest[Int] = implicitly[Manifest[Int]]
  val TrainingDataFrameField: TField = new TField("trainingDataFrame", TType.STRUCT, 5)
  val TrainingDataFrameFieldManifest: Manifest[modeldb.DataFrame] = implicitly[Manifest[modeldb.DataFrame]]
  val SpecificationField: TField = new TField("specification", TType.STRUCT, 6)
  val SpecificationFieldManifest: Manifest[modeldb.TransformerSpec] = implicitly[Manifest[modeldb.TransformerSpec]]
  val ProblemTypeField: TField = new TField("problemType", TType.ENUM, 7)
  val ProblemTypeFieldI32: TField = new TField("problemType", TType.I32, 7)
  val ProblemTypeFieldManifest: Manifest[modeldb.ProblemType] = implicitly[Manifest[modeldb.ProblemType]]
  val FeatureColumnsField: TField = new TField("featureColumns", TType.LIST, 8)
  val FeatureColumnsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val LabelColumnsField: TField = new TField("labelColumns", TType.LIST, 9)
  val LabelColumnsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val PredictionColumnsField: TField = new TField("predictionColumns", TType.LIST, 10)
  val PredictionColumnsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val MetricsField: TField = new TField("metrics", TType.MAP, 11)
  val MetricsFieldManifest: Manifest[Map[String, Map[Int, Double]]] = implicitly[Manifest[Map[String, Map[Int, Double]]]]
  val AnnotationsField: TField = new TField("annotations", TType.LIST, 12)
  val AnnotationsFieldManifest: Manifest[Seq[String]] = implicitly[Manifest[Seq[String]]]
  val ShaField: TField = new TField("sha", TType.STRING, 13)
  val ShaFieldManifest: Manifest[String] = implicitly[Manifest[String]]
  val FilepathField: TField = new TField("filepath", TType.STRING, 14)
  val FilepathFieldManifest: Manifest[String] = implicitly[Manifest[String]]
  val TimestampField: TField = new TField("timestamp", TType.STRING, 15)
  val TimestampFieldManifest: Manifest[String] = implicitly[Manifest[String]]
  val LinearModelDataField: TField = new TField("linearModelData", TType.STRUCT, 16)
  val LinearModelDataFieldManifest: Manifest[modeldb.LinearModel] = implicitly[Manifest[modeldb.LinearModel]]
  val MetadataField: TField = new TField("metadata", TType.STRING, 17)
  val MetadataFieldManifest: Manifest[String] = implicitly[Manifest[String]]

  /**
   * Field information in declaration order.
   */
  lazy val fieldInfos: scala.List[ThriftStructFieldInfo] = scala.List[ThriftStructFieldInfo](
    new ThriftStructFieldInfo(
      IdField,
      false,
      false,
      IdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ExperimentRunIdField,
      false,
      false,
      ExperimentRunIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ExperimentIdField,
      false,
      false,
      ExperimentIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ProjectIdField,
      false,
      false,
      ProjectIdFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      TrainingDataFrameField,
      false,
      false,
      TrainingDataFrameFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      SpecificationField,
      false,
      false,
      SpecificationFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ProblemTypeField,
      false,
      false,
      ProblemTypeFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      FeatureColumnsField,
      false,
      false,
      FeatureColumnsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      LabelColumnsField,
      false,
      false,
      LabelColumnsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      PredictionColumnsField,
      false,
      false,
      PredictionColumnsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      MetricsField,
      false,
      false,
      MetricsFieldManifest,
      _root_.scala.Some(implicitly[Manifest[String]]),
      _root_.scala.Some(implicitly[Manifest[Map[Int, Double]]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      AnnotationsField,
      false,
      false,
      AnnotationsFieldManifest,
      _root_.scala.None,
      _root_.scala.Some(implicitly[Manifest[String]]),
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      ShaField,
      false,
      false,
      ShaFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      FilepathField,
      false,
      false,
      FilepathFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      TimestampField,
      false,
      false,
      TimestampFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      LinearModelDataField,
      true,
      false,
      LinearModelDataFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    ),
    new ThriftStructFieldInfo(
      MetadataField,
      true,
      false,
      MetadataFieldManifest,
      _root_.scala.None,
      _root_.scala.None,
      immutable$Map.empty[String, String],
      immutable$Map.empty[String, String],
      None
    )
  )

  lazy val structAnnotations: immutable$Map[String, String] =
    immutable$Map.empty[String, String]

  /**
   * Checks that all required fields are non-null.
   */
  def validate(_item: ModelResponse): Unit = {
  }

  /**
   * Checks that the struct is a valid as a new instance. If there are any missing required or
   * construction required fields, return a non-empty list.
   */
  def validateNewInstance(item: ModelResponse): scala.Seq[com.twitter.scrooge.validation.Issue] = {
    val buf = scala.collection.mutable.ListBuffer.empty[com.twitter.scrooge.validation.Issue]

    buf ++= validateField(item.id)
    buf ++= validateField(item.experimentRunId)
    buf ++= validateField(item.experimentId)
    buf ++= validateField(item.projectId)
    buf ++= validateField(item.trainingDataFrame)
    buf ++= validateField(item.specification)
    buf ++= validateField(item.problemType)
    buf ++= validateField(item.featureColumns)
    buf ++= validateField(item.labelColumns)
    buf ++= validateField(item.predictionColumns)
    buf ++= validateField(item.metrics)
    buf ++= validateField(item.annotations)
    buf ++= validateField(item.sha)
    buf ++= validateField(item.filepath)
    buf ++= validateField(item.timestamp)
    buf ++= validateField(item.linearModelData)
    buf ++= validateField(item.metadata)
    buf.toList
  }

  def withoutPassthroughFields(original: ModelResponse): ModelResponse =
    new Immutable(
      id =
        {
          val field = original.id
          field
        },
      experimentRunId =
        {
          val field = original.experimentRunId
          field
        },
      experimentId =
        {
          val field = original.experimentId
          field
        },
      projectId =
        {
          val field = original.projectId
          field
        },
      trainingDataFrame =
        {
          val field = original.trainingDataFrame
          modeldb.DataFrame.withoutPassthroughFields(field)
        },
      specification =
        {
          val field = original.specification
          modeldb.TransformerSpec.withoutPassthroughFields(field)
        },
      problemType =
        {
          val field = original.problemType
          field
        },
      featureColumns =
        {
          val field = original.featureColumns
          field.map { field =>
            field
          }
        },
      labelColumns =
        {
          val field = original.labelColumns
          field.map { field =>
            field
          }
        },
      predictionColumns =
        {
          val field = original.predictionColumns
          field.map { field =>
            field
          }
        },
      metrics =
        {
          val field = original.metrics
          field.map { case (key, value) =>
              val newKey = {
              val field = key
              field
            }
  
          
              val newValue = {
              val field = value
              field.map { case (key, value) =>
                    val newKey = {
                    val field = key
                    field
                  }
  
      
                    val newValue = {
                    val field = value
                    field
                  }
  
      
                  newKey -> newValue
                }
            }
  
          
            newKey -> newValue
          }
        },
      annotations =
        {
          val field = original.annotations
          field.map { field =>
            field
          }
        },
      sha =
        {
          val field = original.sha
          field
        },
      filepath =
        {
          val field = original.filepath
          field
        },
      timestamp =
        {
          val field = original.timestamp
          field
        },
      linearModelData =
        {
          val field = original.linearModelData
          field.map { field =>
            modeldb.LinearModel.withoutPassthroughFields(field)
          }
        },
      metadata =
        {
          val field = original.metadata
          field.map { field =>
            field
          }
        }
    )

  override def encode(_item: ModelResponse, _oproto: TProtocol): Unit = {
    _item.write(_oproto)
  }


  private[this] def lazyDecode(_iprot: LazyTProtocol): ModelResponse = {

    var id: Int = 0
    var experimentRunId: Int = 0
    var experimentId: Int = 0
    var projectId: Int = 0
    var trainingDataFrame: modeldb.DataFrame = null
    var specification: modeldb.TransformerSpec = null
    var problemType: modeldb.ProblemType = null
    var featureColumns: Seq[String] = Seq[String]()
    var labelColumns: Seq[String] = Seq[String]()
    var predictionColumns: Seq[String] = Seq[String]()
    var metrics: Map[String, Map[Int, Double]] = Map[String, Map[Int, Double]]()
    var annotations: Seq[String] = Seq[String]()
    var shaOffset: Int = -1
    var filepathOffset: Int = -1
    var timestampOffset: Int = -1
    var linearModelData: Option[modeldb.LinearModel] = None
    var metadataOffset: Int = -1

    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false
    val _start_offset = _iprot.offset

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.I32 =>
    
                id = readIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'id' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.I32 =>
    
                experimentRunId = readExperimentRunIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'experimentRunId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.I32 =>
    
                experimentId = readExperimentIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'experimentId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.I32 =>
    
                projectId = readProjectIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'projectId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                trainingDataFrame = readTrainingDataFrameValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'trainingDataFrame' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 6 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                specification = readSpecificationValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'specification' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 7 =>
            _field.`type` match {
              case TType.I32 | TType.ENUM =>
    
                problemType = readProblemTypeValue(_iprot)
              case _actualType =>
                val _expectedType = TType.ENUM
                throw new TProtocolException(
                  "Received wrong type for field 'problemType' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 8 =>
            _field.`type` match {
              case TType.LIST =>
    
                featureColumns = readFeatureColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'featureColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 9 =>
            _field.`type` match {
              case TType.LIST =>
    
                labelColumns = readLabelColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'labelColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 10 =>
            _field.`type` match {
              case TType.LIST =>
    
                predictionColumns = readPredictionColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'predictionColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 11 =>
            _field.`type` match {
              case TType.MAP =>
    
                metrics = readMetricsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.MAP
                throw new TProtocolException(
                  "Received wrong type for field 'metrics' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 12 =>
            _field.`type` match {
              case TType.LIST =>
    
                annotations = readAnnotationsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'annotations' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 13 =>
            _field.`type` match {
              case TType.STRING =>
                shaOffset = _iprot.offsetSkipString
    
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'sha' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 14 =>
            _field.`type` match {
              case TType.STRING =>
                filepathOffset = _iprot.offsetSkipString
    
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'filepath' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 15 =>
            _field.`type` match {
              case TType.STRING =>
                timestampOffset = _iprot.offsetSkipString
    
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'timestamp' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 16 =>
            _field.`type` match {
              case TType.STRUCT =>
    
                linearModelData = Some(readLinearModelDataValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'linearModelData' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 17 =>
            _field.`type` match {
              case TType.STRING =>
                metadataOffset = _iprot.offsetSkipString
    
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'metadata' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    new LazyImmutable(
      _iprot,
      _iprot.buffer,
      _start_offset,
      _iprot.offset,
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      shaOffset,
      filepathOffset,
      timestampOffset,
      linearModelData,
      metadataOffset,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  override def decode(_iprot: TProtocol): ModelResponse =
    _iprot match {
      case i: LazyTProtocol => lazyDecode(i)
      case i => eagerDecode(i)
    }

  private[modeldb] def eagerDecode(_iprot: TProtocol): ModelResponse = {
    var id: Int = 0
    var experimentRunId: Int = 0
    var experimentId: Int = 0
    var projectId: Int = 0
    var trainingDataFrame: modeldb.DataFrame = null
    var specification: modeldb.TransformerSpec = null
    var problemType: modeldb.ProblemType = null
    var featureColumns: Seq[String] = Seq[String]()
    var labelColumns: Seq[String] = Seq[String]()
    var predictionColumns: Seq[String] = Seq[String]()
    var metrics: Map[String, Map[Int, Double]] = Map[String, Map[Int, Double]]()
    var annotations: Seq[String] = Seq[String]()
    var sha: String = null
    var filepath: String = null
    var timestamp: String = null
    var linearModelData: _root_.scala.Option[modeldb.LinearModel] = _root_.scala.None
    var metadata: _root_.scala.Option[String] = _root_.scala.None
    var _passthroughFields: Builder[(Short, TFieldBlob), immutable$Map[Short, TFieldBlob]] = null
    var _done = false

    _iprot.readStructBegin()
    while (!_done) {
      val _field = _iprot.readFieldBegin()
      if (_field.`type` == TType.STOP) {
        _done = true
      } else {
        _field.id match {
          case 1 =>
            _field.`type` match {
              case TType.I32 =>
                id = readIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'id' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 2 =>
            _field.`type` match {
              case TType.I32 =>
                experimentRunId = readExperimentRunIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'experimentRunId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 3 =>
            _field.`type` match {
              case TType.I32 =>
                experimentId = readExperimentIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'experimentId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 4 =>
            _field.`type` match {
              case TType.I32 =>
                projectId = readProjectIdValue(_iprot)
              case _actualType =>
                val _expectedType = TType.I32
                throw new TProtocolException(
                  "Received wrong type for field 'projectId' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 5 =>
            _field.`type` match {
              case TType.STRUCT =>
                trainingDataFrame = readTrainingDataFrameValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'trainingDataFrame' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 6 =>
            _field.`type` match {
              case TType.STRUCT =>
                specification = readSpecificationValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'specification' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 7 =>
            _field.`type` match {
              case TType.I32 | TType.ENUM =>
                problemType = readProblemTypeValue(_iprot)
              case _actualType =>
                val _expectedType = TType.ENUM
                throw new TProtocolException(
                  "Received wrong type for field 'problemType' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 8 =>
            _field.`type` match {
              case TType.LIST =>
                featureColumns = readFeatureColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'featureColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 9 =>
            _field.`type` match {
              case TType.LIST =>
                labelColumns = readLabelColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'labelColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 10 =>
            _field.`type` match {
              case TType.LIST =>
                predictionColumns = readPredictionColumnsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'predictionColumns' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 11 =>
            _field.`type` match {
              case TType.MAP =>
                metrics = readMetricsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.MAP
                throw new TProtocolException(
                  "Received wrong type for field 'metrics' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 12 =>
            _field.`type` match {
              case TType.LIST =>
                annotations = readAnnotationsValue(_iprot)
              case _actualType =>
                val _expectedType = TType.LIST
                throw new TProtocolException(
                  "Received wrong type for field 'annotations' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 13 =>
            _field.`type` match {
              case TType.STRING =>
                sha = readShaValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'sha' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 14 =>
            _field.`type` match {
              case TType.STRING =>
                filepath = readFilepathValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'filepath' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 15 =>
            _field.`type` match {
              case TType.STRING =>
                timestamp = readTimestampValue(_iprot)
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'timestamp' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 16 =>
            _field.`type` match {
              case TType.STRUCT =>
                linearModelData = _root_.scala.Some(readLinearModelDataValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRUCT
                throw new TProtocolException(
                  "Received wrong type for field 'linearModelData' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case 17 =>
            _field.`type` match {
              case TType.STRING =>
                metadata = _root_.scala.Some(readMetadataValue(_iprot))
              case _actualType =>
                val _expectedType = TType.STRING
                throw new TProtocolException(
                  "Received wrong type for field 'metadata' (expected=%s, actual=%s).".format(
                    ttypeToString(_expectedType),
                    ttypeToString(_actualType)
                  )
                )
            }
          case _ =>
            if (_passthroughFields == null)
              _passthroughFields = immutable$Map.newBuilder[Short, TFieldBlob]
            _passthroughFields += (_field.id -> TFieldBlob.read(_field, _iprot))
        }
        _iprot.readFieldEnd()
      }
    }
    _iprot.readStructEnd()

    new Immutable(
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata,
      if (_passthroughFields == null)
        NoPassthroughFields
      else
        _passthroughFields.result()
    )
  }

  def apply(
    id: Int,
    experimentRunId: Int,
    experimentId: Int,
    projectId: Int,
    trainingDataFrame: modeldb.DataFrame,
    specification: modeldb.TransformerSpec,
    problemType: modeldb.ProblemType,
    featureColumns: Seq[String] = Seq[String](),
    labelColumns: Seq[String] = Seq[String](),
    predictionColumns: Seq[String] = Seq[String](),
    metrics: Map[String, Map[Int, Double]] = Map[String, Map[Int, Double]](),
    annotations: Seq[String] = Seq[String](),
    sha: String,
    filepath: String,
    timestamp: String,
    linearModelData: _root_.scala.Option[modeldb.LinearModel] = _root_.scala.None,
    metadata: _root_.scala.Option[String] = _root_.scala.None
  ): ModelResponse =
    new Immutable(
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata
    )

  def unapply(_item: ModelResponse): _root_.scala.Option[_root_.scala.Tuple17[Int, Int, Int, Int, modeldb.DataFrame, modeldb.TransformerSpec, modeldb.ProblemType, Seq[String], Seq[String], Seq[String], Map[String, Map[Int, Double]], Seq[String], String, String, String, Option[modeldb.LinearModel], Option[String]]] = _root_.scala.Some(_item.toTuple)


  @inline private[modeldb] def readIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeIdField(id_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(IdField)
    writeIdValue(id_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeIdValue(id_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(id_item)
  }

  @inline private[modeldb] def readExperimentRunIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeExperimentRunIdField(experimentRunId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ExperimentRunIdField)
    writeExperimentRunIdValue(experimentRunId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeExperimentRunIdValue(experimentRunId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(experimentRunId_item)
  }

  @inline private[modeldb] def readExperimentIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeExperimentIdField(experimentId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ExperimentIdField)
    writeExperimentIdValue(experimentId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeExperimentIdValue(experimentId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(experimentId_item)
  }

  @inline private[modeldb] def readProjectIdValue(_iprot: TProtocol): Int = {
    _iprot.readI32()
  }

  @inline private def writeProjectIdField(projectId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ProjectIdField)
    writeProjectIdValue(projectId_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeProjectIdValue(projectId_item: Int, _oprot: TProtocol): Unit = {
    _oprot.writeI32(projectId_item)
  }

  @inline private[modeldb] def readTrainingDataFrameValue(_iprot: TProtocol): modeldb.DataFrame = {
    modeldb.DataFrame.decode(_iprot)
  }

  @inline private def writeTrainingDataFrameField(trainingDataFrame_item: modeldb.DataFrame, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(TrainingDataFrameField)
    writeTrainingDataFrameValue(trainingDataFrame_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeTrainingDataFrameValue(trainingDataFrame_item: modeldb.DataFrame, _oprot: TProtocol): Unit = {
    trainingDataFrame_item.write(_oprot)
  }

  @inline private[modeldb] def readSpecificationValue(_iprot: TProtocol): modeldb.TransformerSpec = {
    modeldb.TransformerSpec.decode(_iprot)
  }

  @inline private def writeSpecificationField(specification_item: modeldb.TransformerSpec, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(SpecificationField)
    writeSpecificationValue(specification_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeSpecificationValue(specification_item: modeldb.TransformerSpec, _oprot: TProtocol): Unit = {
    specification_item.write(_oprot)
  }

  @inline private[modeldb] def readProblemTypeValue(_iprot: TProtocol): modeldb.ProblemType = {
    modeldb.ProblemType.getOrUnknown(_iprot.readI32())
  }

  @inline private def writeProblemTypeField(problemType_item: modeldb.ProblemType, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ProblemTypeFieldI32)
    writeProblemTypeValue(problemType_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeProblemTypeValue(problemType_item: modeldb.ProblemType, _oprot: TProtocol): Unit = {
    _oprot.writeI32(problemType_item.value)
  }

  @inline private[modeldb] def readFeatureColumnsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writeFeatureColumnsField(featureColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(FeatureColumnsField)
    writeFeatureColumnsValue(featureColumns_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeFeatureColumnsValue(featureColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, featureColumns_item.size))
    featureColumns_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = featureColumns_item.size
        while (_i < _size) {
          val featureColumns_item_element = featureColumns_item(_i)
          _oprot.writeString(featureColumns_item_element)
          _i += 1
        }
      case _ =>
        featureColumns_item.foreach { featureColumns_item_element =>
          _oprot.writeString(featureColumns_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readLabelColumnsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writeLabelColumnsField(labelColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(LabelColumnsField)
    writeLabelColumnsValue(labelColumns_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeLabelColumnsValue(labelColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, labelColumns_item.size))
    labelColumns_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = labelColumns_item.size
        while (_i < _size) {
          val labelColumns_item_element = labelColumns_item(_i)
          _oprot.writeString(labelColumns_item_element)
          _i += 1
        }
      case _ =>
        labelColumns_item.foreach { labelColumns_item_element =>
          _oprot.writeString(labelColumns_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readPredictionColumnsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writePredictionColumnsField(predictionColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(PredictionColumnsField)
    writePredictionColumnsValue(predictionColumns_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writePredictionColumnsValue(predictionColumns_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, predictionColumns_item.size))
    predictionColumns_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = predictionColumns_item.size
        while (_i < _size) {
          val predictionColumns_item_element = predictionColumns_item(_i)
          _oprot.writeString(predictionColumns_item_element)
          _i += 1
        }
      case _ =>
        predictionColumns_item.foreach { predictionColumns_item_element =>
          _oprot.writeString(predictionColumns_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readMetricsValue(_iprot: TProtocol): Map[String, Map[Int, Double]] = {
    val _map = _iprot.readMapBegin()
    if (_map.size == 0) {
      _iprot.readMapEnd()
      Map.empty[String, Map[Int, Double]]
    } else {
      val _rv = new mutable$HashMap[String, Map[Int, Double]]
      var _i = 0
      while (_i < _map.size) {
        val _key = {
          _iprot.readString()
        }
        val _value = {
          val _map = _iprot.readMapBegin()
          if (_map.size == 0) {
            _iprot.readMapEnd()
            Map.empty[Int, Double]
          } else {
            val _rv = new mutable$HashMap[Int, Double]
            var _i = 0
            while (_i < _map.size) {
              val _key = {
                _iprot.readI32()
              }
              val _value = {
                _iprot.readDouble()
              }
              _rv(_key) = _value
              _i += 1
            }
            _iprot.readMapEnd()
            _rv
          }
        }
        _rv(_key) = _value
        _i += 1
      }
      _iprot.readMapEnd()
      _rv
    }
  }

  @inline private def writeMetricsField(metrics_item: Map[String, Map[Int, Double]], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(MetricsField)
    writeMetricsValue(metrics_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeMetricsValue(metrics_item: Map[String, Map[Int, Double]], _oprot: TProtocol): Unit = {
    _oprot.writeMapBegin(new TMap(TType.STRING, TType.MAP, metrics_item.size))
    metrics_item.foreach { case (metrics_item_key, metrics_item_value) =>
      _oprot.writeString(metrics_item_key)
      _oprot.writeMapBegin(new TMap(TType.I32, TType.DOUBLE, metrics_item_value.size))
      metrics_item_value.foreach { case (metrics_item_value_key, metrics_item_value_value) =>
        _oprot.writeI32(metrics_item_value_key)
        _oprot.writeDouble(metrics_item_value_value)
      }
      _oprot.writeMapEnd()
    }
    _oprot.writeMapEnd()
  }

  @inline private[modeldb] def readAnnotationsValue(_iprot: TProtocol): Seq[String] = {
    val _list = _iprot.readListBegin()
    if (_list.size == 0) {
      _iprot.readListEnd()
      Nil
    } else {
      val _rv = new mutable$ArrayBuffer[String](_list.size)
      var _i = 0
      while (_i < _list.size) {
        _rv += {
          _iprot.readString()
        }
        _i += 1
      }
      _iprot.readListEnd()
      _rv
    }
  }

  @inline private def writeAnnotationsField(annotations_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(AnnotationsField)
    writeAnnotationsValue(annotations_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeAnnotationsValue(annotations_item: Seq[String], _oprot: TProtocol): Unit = {
    _oprot.writeListBegin(new TList(TType.STRING, annotations_item.size))
    annotations_item match {
      case _: IndexedSeq[_] =>
        var _i = 0
        val _size = annotations_item.size
        while (_i < _size) {
          val annotations_item_element = annotations_item(_i)
          _oprot.writeString(annotations_item_element)
          _i += 1
        }
      case _ =>
        annotations_item.foreach { annotations_item_element =>
          _oprot.writeString(annotations_item_element)
        }
    }
    _oprot.writeListEnd()
  }

  @inline private[modeldb] def readShaValue(_iprot: TProtocol): String = {
    _iprot.readString()
  }

  @inline private def writeShaField(sha_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(ShaField)
    writeShaValue(sha_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeShaValue(sha_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeString(sha_item)
  }

  @inline private[modeldb] def readFilepathValue(_iprot: TProtocol): String = {
    _iprot.readString()
  }

  @inline private def writeFilepathField(filepath_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(FilepathField)
    writeFilepathValue(filepath_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeFilepathValue(filepath_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeString(filepath_item)
  }

  @inline private[modeldb] def readTimestampValue(_iprot: TProtocol): String = {
    _iprot.readString()
  }

  @inline private def writeTimestampField(timestamp_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(TimestampField)
    writeTimestampValue(timestamp_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeTimestampValue(timestamp_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeString(timestamp_item)
  }

  @inline private[modeldb] def readLinearModelDataValue(_iprot: TProtocol): modeldb.LinearModel = {
    modeldb.LinearModel.decode(_iprot)
  }

  @inline private def writeLinearModelDataField(linearModelData_item: modeldb.LinearModel, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(LinearModelDataField)
    writeLinearModelDataValue(linearModelData_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeLinearModelDataValue(linearModelData_item: modeldb.LinearModel, _oprot: TProtocol): Unit = {
    linearModelData_item.write(_oprot)
  }

  @inline private[modeldb] def readMetadataValue(_iprot: TProtocol): String = {
    _iprot.readString()
  }

  @inline private def writeMetadataField(metadata_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeFieldBegin(MetadataField)
    writeMetadataValue(metadata_item, _oprot)
    _oprot.writeFieldEnd()
  }

  @inline private def writeMetadataValue(metadata_item: String, _oprot: TProtocol): Unit = {
    _oprot.writeString(metadata_item)
  }


  object Immutable extends ThriftStructCodec3[ModelResponse] {
    override def encode(_item: ModelResponse, _oproto: TProtocol): Unit = { _item.write(_oproto) }
    override def decode(_iprot: TProtocol): ModelResponse = ModelResponse.decode(_iprot)
    override lazy val metaData: ThriftStructMetaData[ModelResponse] = ModelResponse.metaData
  }

  /**
   * The default read-only implementation of ModelResponse.  You typically should not need to
   * directly reference this class; instead, use the ModelResponse.apply method to construct
   * new instances.
   */
  class Immutable(
      val id: Int,
      val experimentRunId: Int,
      val experimentId: Int,
      val projectId: Int,
      val trainingDataFrame: modeldb.DataFrame,
      val specification: modeldb.TransformerSpec,
      val problemType: modeldb.ProblemType,
      val featureColumns: Seq[String],
      val labelColumns: Seq[String],
      val predictionColumns: Seq[String],
      val metrics: Map[String, Map[Int, Double]],
      val annotations: Seq[String],
      val sha: String,
      val filepath: String,
      val timestamp: String,
      val linearModelData: _root_.scala.Option[modeldb.LinearModel],
      val metadata: _root_.scala.Option[String],
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends ModelResponse {
    def this(
      id: Int,
      experimentRunId: Int,
      experimentId: Int,
      projectId: Int,
      trainingDataFrame: modeldb.DataFrame,
      specification: modeldb.TransformerSpec,
      problemType: modeldb.ProblemType,
      featureColumns: Seq[String] = Seq[String](),
      labelColumns: Seq[String] = Seq[String](),
      predictionColumns: Seq[String] = Seq[String](),
      metrics: Map[String, Map[Int, Double]] = Map[String, Map[Int, Double]](),
      annotations: Seq[String] = Seq[String](),
      sha: String,
      filepath: String,
      timestamp: String,
      linearModelData: _root_.scala.Option[modeldb.LinearModel] = _root_.scala.None,
      metadata: _root_.scala.Option[String] = _root_.scala.None
    ) = this(
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata,
      Map.empty[Short, TFieldBlob]
    )
  }

  /**
   * This is another Immutable, this however keeps strings as lazy values that are lazily decoded from the backing
   * array byte on read.
   */
  private[this] class LazyImmutable(
      _proto: LazyTProtocol,
      _buf: Array[Byte],
      _start_offset: Int,
      _end_offset: Int,
      val id: Int,
      val experimentRunId: Int,
      val experimentId: Int,
      val projectId: Int,
      val trainingDataFrame: modeldb.DataFrame,
      val specification: modeldb.TransformerSpec,
      val problemType: modeldb.ProblemType,
      val featureColumns: Seq[String],
      val labelColumns: Seq[String],
      val predictionColumns: Seq[String],
      val metrics: Map[String, Map[Int, Double]],
      val annotations: Seq[String],
      shaOffset: Int,
      filepathOffset: Int,
      timestampOffset: Int,
      val linearModelData: _root_.scala.Option[modeldb.LinearModel],
      metadataOffset: Int,
      override val _passthroughFields: immutable$Map[Short, TFieldBlob])
    extends ModelResponse {

    override def write(_oprot: TProtocol): Unit = {
      _oprot match {
        case i: LazyTProtocol => i.writeRaw(_buf, _start_offset, _end_offset - _start_offset)
        case _ => super.write(_oprot)
      }
    }

    lazy val sha: String =
      if (shaOffset == -1)
        null
      else {
        _proto.decodeString(_buf, shaOffset)
      }
    lazy val filepath: String =
      if (filepathOffset == -1)
        null
      else {
        _proto.decodeString(_buf, filepathOffset)
      }
    lazy val timestamp: String =
      if (timestampOffset == -1)
        null
      else {
        _proto.decodeString(_buf, timestampOffset)
      }
    lazy val metadata: _root_.scala.Option[String] =
      if (metadataOffset == -1)
        None
      else {
        Some(_proto.decodeString(_buf, metadataOffset))
      }

    /**
     * Override the super hash code to make it a lazy val rather than def.
     *
     * Calculating the hash code can be expensive, caching it where possible
     * can provide significant performance wins. (Key in a hash map for instance)
     * Usually not safe since the normal constructor will accept a mutable map or
     * set as an arg
     * Here however we control how the class is generated from serialized data.
     * With the class private and the contract that we throw away our mutable references
     * having the hash code lazy here is safe.
     */
    override lazy val hashCode = super.hashCode
  }

  /**
   * This Proxy trait allows you to extend the ModelResponse trait with additional state or
   * behavior and implement the read-only methods from ModelResponse using an underlying
   * instance.
   */
  trait Proxy extends ModelResponse {
    protected def _underlying_ModelResponse: ModelResponse
    override def id: Int = _underlying_ModelResponse.id
    override def experimentRunId: Int = _underlying_ModelResponse.experimentRunId
    override def experimentId: Int = _underlying_ModelResponse.experimentId
    override def projectId: Int = _underlying_ModelResponse.projectId
    override def trainingDataFrame: modeldb.DataFrame = _underlying_ModelResponse.trainingDataFrame
    override def specification: modeldb.TransformerSpec = _underlying_ModelResponse.specification
    override def problemType: modeldb.ProblemType = _underlying_ModelResponse.problemType
    override def featureColumns: Seq[String] = _underlying_ModelResponse.featureColumns
    override def labelColumns: Seq[String] = _underlying_ModelResponse.labelColumns
    override def predictionColumns: Seq[String] = _underlying_ModelResponse.predictionColumns
    override def metrics: Map[String, Map[Int, Double]] = _underlying_ModelResponse.metrics
    override def annotations: Seq[String] = _underlying_ModelResponse.annotations
    override def sha: String = _underlying_ModelResponse.sha
    override def filepath: String = _underlying_ModelResponse.filepath
    override def timestamp: String = _underlying_ModelResponse.timestamp
    override def linearModelData: _root_.scala.Option[modeldb.LinearModel] = _underlying_ModelResponse.linearModelData
    override def metadata: _root_.scala.Option[String] = _underlying_ModelResponse.metadata
    override def _passthroughFields: immutable$Map[Short, TFieldBlob] = _underlying_ModelResponse._passthroughFields
  }
}

/**
 * Prefer the companion object's [[modeldb.ModelResponse.apply]]
 * for construction if you don't need to specify passthrough fields.
 */
trait ModelResponse
  extends ThriftStruct
  with _root_.scala.Product17[Int, Int, Int, Int, modeldb.DataFrame, modeldb.TransformerSpec, modeldb.ProblemType, Seq[String], Seq[String], Seq[String], Map[String, Map[Int, Double]], Seq[String], String, String, String, Option[modeldb.LinearModel], Option[String]]
  with ValidatingThriftStruct[ModelResponse]
  with java.io.Serializable
{
  import ModelResponse._

  def id: Int
  def experimentRunId: Int
  def experimentId: Int
  def projectId: Int
  def trainingDataFrame: modeldb.DataFrame
  def specification: modeldb.TransformerSpec
  def problemType: modeldb.ProblemType
  def featureColumns: Seq[String]
  def labelColumns: Seq[String]
  def predictionColumns: Seq[String]
  def metrics: Map[String, Map[Int, Double]]
  def annotations: Seq[String]
  def sha: String
  def filepath: String
  def timestamp: String
  def linearModelData: _root_.scala.Option[modeldb.LinearModel]
  def metadata: _root_.scala.Option[String]

  def _passthroughFields: immutable$Map[Short, TFieldBlob] = immutable$Map.empty

  def _1: Int = id
  def _2: Int = experimentRunId
  def _3: Int = experimentId
  def _4: Int = projectId
  def _5: modeldb.DataFrame = trainingDataFrame
  def _6: modeldb.TransformerSpec = specification
  def _7: modeldb.ProblemType = problemType
  def _8: Seq[String] = featureColumns
  def _9: Seq[String] = labelColumns
  def _10: Seq[String] = predictionColumns
  def _11: Map[String, Map[Int, Double]] = metrics
  def _12: Seq[String] = annotations
  def _13: String = sha
  def _14: String = filepath
  def _15: String = timestamp
  def _16: _root_.scala.Option[modeldb.LinearModel] = linearModelData
  def _17: _root_.scala.Option[String] = metadata

  def toTuple: _root_.scala.Tuple17[Int, Int, Int, Int, modeldb.DataFrame, modeldb.TransformerSpec, modeldb.ProblemType, Seq[String], Seq[String], Seq[String], Map[String, Map[Int, Double]], Seq[String], String, String, String, Option[modeldb.LinearModel], Option[String]] = {
    (
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata
    )
  }


  /**
   * Gets a field value encoded as a binary blob using TCompactProtocol.  If the specified field
   * is present in the passthrough map, that value is returned.  Otherwise, if the specified field
   * is known and not optional and set to None, then the field is serialized and returned.
   */
  def getFieldBlob(_fieldId: Short): _root_.scala.Option[TFieldBlob] = {
    lazy val _buff = new TMemoryBuffer(32)
    lazy val _oprot = new TCompactProtocol(_buff)
    _passthroughFields.get(_fieldId) match {
      case blob: _root_.scala.Some[TFieldBlob] => blob
      case _root_.scala.None => {
        val _fieldOpt: _root_.scala.Option[TField] =
          _fieldId match {
            case 1 =>
              if (true) {
                writeIdValue(id, _oprot)
                _root_.scala.Some(ModelResponse.IdField)
              } else {
                _root_.scala.None
              }
            case 2 =>
              if (true) {
                writeExperimentRunIdValue(experimentRunId, _oprot)
                _root_.scala.Some(ModelResponse.ExperimentRunIdField)
              } else {
                _root_.scala.None
              }
            case 3 =>
              if (true) {
                writeExperimentIdValue(experimentId, _oprot)
                _root_.scala.Some(ModelResponse.ExperimentIdField)
              } else {
                _root_.scala.None
              }
            case 4 =>
              if (true) {
                writeProjectIdValue(projectId, _oprot)
                _root_.scala.Some(ModelResponse.ProjectIdField)
              } else {
                _root_.scala.None
              }
            case 5 =>
              if (trainingDataFrame ne null) {
                writeTrainingDataFrameValue(trainingDataFrame, _oprot)
                _root_.scala.Some(ModelResponse.TrainingDataFrameField)
              } else {
                _root_.scala.None
              }
            case 6 =>
              if (specification ne null) {
                writeSpecificationValue(specification, _oprot)
                _root_.scala.Some(ModelResponse.SpecificationField)
              } else {
                _root_.scala.None
              }
            case 7 =>
              if (problemType ne null) {
                writeProblemTypeValue(problemType, _oprot)
                _root_.scala.Some(ModelResponse.ProblemTypeField)
              } else {
                _root_.scala.None
              }
            case 8 =>
              if (featureColumns ne null) {
                writeFeatureColumnsValue(featureColumns, _oprot)
                _root_.scala.Some(ModelResponse.FeatureColumnsField)
              } else {
                _root_.scala.None
              }
            case 9 =>
              if (labelColumns ne null) {
                writeLabelColumnsValue(labelColumns, _oprot)
                _root_.scala.Some(ModelResponse.LabelColumnsField)
              } else {
                _root_.scala.None
              }
            case 10 =>
              if (predictionColumns ne null) {
                writePredictionColumnsValue(predictionColumns, _oprot)
                _root_.scala.Some(ModelResponse.PredictionColumnsField)
              } else {
                _root_.scala.None
              }
            case 11 =>
              if (metrics ne null) {
                writeMetricsValue(metrics, _oprot)
                _root_.scala.Some(ModelResponse.MetricsField)
              } else {
                _root_.scala.None
              }
            case 12 =>
              if (annotations ne null) {
                writeAnnotationsValue(annotations, _oprot)
                _root_.scala.Some(ModelResponse.AnnotationsField)
              } else {
                _root_.scala.None
              }
            case 13 =>
              if (sha ne null) {
                writeShaValue(sha, _oprot)
                _root_.scala.Some(ModelResponse.ShaField)
              } else {
                _root_.scala.None
              }
            case 14 =>
              if (filepath ne null) {
                writeFilepathValue(filepath, _oprot)
                _root_.scala.Some(ModelResponse.FilepathField)
              } else {
                _root_.scala.None
              }
            case 15 =>
              if (timestamp ne null) {
                writeTimestampValue(timestamp, _oprot)
                _root_.scala.Some(ModelResponse.TimestampField)
              } else {
                _root_.scala.None
              }
            case 16 =>
              if (linearModelData.isDefined) {
                writeLinearModelDataValue(linearModelData.get, _oprot)
                _root_.scala.Some(ModelResponse.LinearModelDataField)
              } else {
                _root_.scala.None
              }
            case 17 =>
              if (metadata.isDefined) {
                writeMetadataValue(metadata.get, _oprot)
                _root_.scala.Some(ModelResponse.MetadataField)
              } else {
                _root_.scala.None
              }
            case _ => _root_.scala.None
          }
        _fieldOpt match {
          case _root_.scala.Some(_field) =>
            _root_.scala.Some(TFieldBlob(_field, Buf.ByteArray.Owned(_buff.getArray())))
          case _root_.scala.None =>
            _root_.scala.None
        }
      }
    }
  }

  /**
   * Collects TCompactProtocol-encoded field values according to `getFieldBlob` into a map.
   */
  def getFieldBlobs(ids: TraversableOnce[Short]): immutable$Map[Short, TFieldBlob] =
    (ids flatMap { id => getFieldBlob(id) map { id -> _ } }).toMap

  /**
   * Sets a field using a TCompactProtocol-encoded binary blob.  If the field is a known
   * field, the blob is decoded and the field is set to the decoded value.  If the field
   * is unknown and passthrough fields are enabled, then the blob will be stored in
   * _passthroughFields.
   */
  def setField(_blob: TFieldBlob): ModelResponse = {
    var id: Int = this.id
    var experimentRunId: Int = this.experimentRunId
    var experimentId: Int = this.experimentId
    var projectId: Int = this.projectId
    var trainingDataFrame: modeldb.DataFrame = this.trainingDataFrame
    var specification: modeldb.TransformerSpec = this.specification
    var problemType: modeldb.ProblemType = this.problemType
    var featureColumns: Seq[String] = this.featureColumns
    var labelColumns: Seq[String] = this.labelColumns
    var predictionColumns: Seq[String] = this.predictionColumns
    var metrics: Map[String, Map[Int, Double]] = this.metrics
    var annotations: Seq[String] = this.annotations
    var sha: String = this.sha
    var filepath: String = this.filepath
    var timestamp: String = this.timestamp
    var linearModelData: _root_.scala.Option[modeldb.LinearModel] = this.linearModelData
    var metadata: _root_.scala.Option[String] = this.metadata
    var _passthroughFields = this._passthroughFields
    _blob.id match {
      case 1 =>
        id = readIdValue(_blob.read)
      case 2 =>
        experimentRunId = readExperimentRunIdValue(_blob.read)
      case 3 =>
        experimentId = readExperimentIdValue(_blob.read)
      case 4 =>
        projectId = readProjectIdValue(_blob.read)
      case 5 =>
        trainingDataFrame = readTrainingDataFrameValue(_blob.read)
      case 6 =>
        specification = readSpecificationValue(_blob.read)
      case 7 =>
        problemType = readProblemTypeValue(_blob.read)
      case 8 =>
        featureColumns = readFeatureColumnsValue(_blob.read)
      case 9 =>
        labelColumns = readLabelColumnsValue(_blob.read)
      case 10 =>
        predictionColumns = readPredictionColumnsValue(_blob.read)
      case 11 =>
        metrics = readMetricsValue(_blob.read)
      case 12 =>
        annotations = readAnnotationsValue(_blob.read)
      case 13 =>
        sha = readShaValue(_blob.read)
      case 14 =>
        filepath = readFilepathValue(_blob.read)
      case 15 =>
        timestamp = readTimestampValue(_blob.read)
      case 16 =>
        linearModelData = _root_.scala.Some(readLinearModelDataValue(_blob.read))
      case 17 =>
        metadata = _root_.scala.Some(readMetadataValue(_blob.read))
      case _ => _passthroughFields += (_blob.id -> _blob)
    }
    new Immutable(
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata,
      _passthroughFields
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetField(_fieldId: Short): ModelResponse = {
    var id: Int = this.id
    var experimentRunId: Int = this.experimentRunId
    var experimentId: Int = this.experimentId
    var projectId: Int = this.projectId
    var trainingDataFrame: modeldb.DataFrame = this.trainingDataFrame
    var specification: modeldb.TransformerSpec = this.specification
    var problemType: modeldb.ProblemType = this.problemType
    var featureColumns: Seq[String] = this.featureColumns
    var labelColumns: Seq[String] = this.labelColumns
    var predictionColumns: Seq[String] = this.predictionColumns
    var metrics: Map[String, Map[Int, Double]] = this.metrics
    var annotations: Seq[String] = this.annotations
    var sha: String = this.sha
    var filepath: String = this.filepath
    var timestamp: String = this.timestamp
    var linearModelData: _root_.scala.Option[modeldb.LinearModel] = this.linearModelData
    var metadata: _root_.scala.Option[String] = this.metadata

    _fieldId match {
      case 1 =>
        id = 0
      case 2 =>
        experimentRunId = 0
      case 3 =>
        experimentId = 0
      case 4 =>
        projectId = 0
      case 5 =>
        trainingDataFrame = null
      case 6 =>
        specification = null
      case 7 =>
        problemType = null
      case 8 =>
        featureColumns = Seq[String]()
      case 9 =>
        labelColumns = Seq[String]()
      case 10 =>
        predictionColumns = Seq[String]()
      case 11 =>
        metrics = Map[String, Map[Int, Double]]()
      case 12 =>
        annotations = Seq[String]()
      case 13 =>
        sha = null
      case 14 =>
        filepath = null
      case 15 =>
        timestamp = null
      case 16 =>
        linearModelData = _root_.scala.None
      case 17 =>
        metadata = _root_.scala.None
      case _ =>
    }
    new Immutable(
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata,
      _passthroughFields - _fieldId
    )
  }

  /**
   * If the specified field is optional, it is set to None.  Otherwise, if the field is
   * known, it is reverted to its default value; if the field is unknown, it is removed
   * from the passthroughFields map, if present.
   */
  def unsetId: ModelResponse = unsetField(1)

  def unsetExperimentRunId: ModelResponse = unsetField(2)

  def unsetExperimentId: ModelResponse = unsetField(3)

  def unsetProjectId: ModelResponse = unsetField(4)

  def unsetTrainingDataFrame: ModelResponse = unsetField(5)

  def unsetSpecification: ModelResponse = unsetField(6)

  def unsetProblemType: ModelResponse = unsetField(7)

  def unsetFeatureColumns: ModelResponse = unsetField(8)

  def unsetLabelColumns: ModelResponse = unsetField(9)

  def unsetPredictionColumns: ModelResponse = unsetField(10)

  def unsetMetrics: ModelResponse = unsetField(11)

  def unsetAnnotations: ModelResponse = unsetField(12)

  def unsetSha: ModelResponse = unsetField(13)

  def unsetFilepath: ModelResponse = unsetField(14)

  def unsetTimestamp: ModelResponse = unsetField(15)

  def unsetLinearModelData: ModelResponse = unsetField(16)

  def unsetMetadata: ModelResponse = unsetField(17)


  override def write(_oprot: TProtocol): Unit = {
    ModelResponse.validate(this)
    _oprot.writeStructBegin(Struct)
    writeIdField(id, _oprot)
    writeExperimentRunIdField(experimentRunId, _oprot)
    writeExperimentIdField(experimentId, _oprot)
    writeProjectIdField(projectId, _oprot)
    if (trainingDataFrame ne null) writeTrainingDataFrameField(trainingDataFrame, _oprot)
    if (specification ne null) writeSpecificationField(specification, _oprot)
    if (problemType ne null) writeProblemTypeField(problemType, _oprot)
    if (featureColumns ne null) writeFeatureColumnsField(featureColumns, _oprot)
    if (labelColumns ne null) writeLabelColumnsField(labelColumns, _oprot)
    if (predictionColumns ne null) writePredictionColumnsField(predictionColumns, _oprot)
    if (metrics ne null) writeMetricsField(metrics, _oprot)
    if (annotations ne null) writeAnnotationsField(annotations, _oprot)
    if (sha ne null) writeShaField(sha, _oprot)
    if (filepath ne null) writeFilepathField(filepath, _oprot)
    if (timestamp ne null) writeTimestampField(timestamp, _oprot)
    if (linearModelData.isDefined) writeLinearModelDataField(linearModelData.get, _oprot)
    if (metadata.isDefined) writeMetadataField(metadata.get, _oprot)
    if (_passthroughFields.nonEmpty) {
      _passthroughFields.values.foreach { _.write(_oprot) }
    }
    _oprot.writeFieldStop()
    _oprot.writeStructEnd()
  }

  def copy(
    id: Int = this.id,
    experimentRunId: Int = this.experimentRunId,
    experimentId: Int = this.experimentId,
    projectId: Int = this.projectId,
    trainingDataFrame: modeldb.DataFrame = this.trainingDataFrame,
    specification: modeldb.TransformerSpec = this.specification,
    problemType: modeldb.ProblemType = this.problemType,
    featureColumns: Seq[String] = this.featureColumns,
    labelColumns: Seq[String] = this.labelColumns,
    predictionColumns: Seq[String] = this.predictionColumns,
    metrics: Map[String, Map[Int, Double]] = this.metrics,
    annotations: Seq[String] = this.annotations,
    sha: String = this.sha,
    filepath: String = this.filepath,
    timestamp: String = this.timestamp,
    linearModelData: _root_.scala.Option[modeldb.LinearModel] = this.linearModelData,
    metadata: _root_.scala.Option[String] = this.metadata,
    _passthroughFields: immutable$Map[Short, TFieldBlob] = this._passthroughFields
  ): ModelResponse =
    new Immutable(
      id,
      experimentRunId,
      experimentId,
      projectId,
      trainingDataFrame,
      specification,
      problemType,
      featureColumns,
      labelColumns,
      predictionColumns,
      metrics,
      annotations,
      sha,
      filepath,
      timestamp,
      linearModelData,
      metadata,
      _passthroughFields
    )

  override def canEqual(other: Any): Boolean = other.isInstanceOf[ModelResponse]

  private def _equals(x: ModelResponse, y: ModelResponse): Boolean =
      x.productArity == y.productArity &&
      x.productIterator.sameElements(y.productIterator) &&
      x._passthroughFields == y._passthroughFields

  override def equals(other: Any): Boolean =
    canEqual(other) &&
      _equals(this, other.asInstanceOf[ModelResponse])

  override def hashCode: Int = {
    var hash = _root_.scala.runtime.ScalaRunTime._hashCode(this)
    hash
  }

  override def toString: String = _root_.scala.runtime.ScalaRunTime._toString(this)


  override def productArity: Int = 17

  override def productElement(n: Int): Any = n match {
    case 0 => this.id
    case 1 => this.experimentRunId
    case 2 => this.experimentId
    case 3 => this.projectId
    case 4 => this.trainingDataFrame
    case 5 => this.specification
    case 6 => this.problemType
    case 7 => this.featureColumns
    case 8 => this.labelColumns
    case 9 => this.predictionColumns
    case 10 => this.metrics
    case 11 => this.annotations
    case 12 => this.sha
    case 13 => this.filepath
    case 14 => this.timestamp
    case 15 => this.linearModelData
    case 16 => this.metadata
    case _ => throw new IndexOutOfBoundsException(n.toString)
  }

  override def productPrefix: String = "ModelResponse"

  def _codec: ValidatingThriftStructCodec3[ModelResponse] = ModelResponse
}

